## Codebase Patterns
- Use uv to manage deps and venv; activate before any execution
- config.yaml sections: proxy, captcha, scraping, retry, database, logging, input_csv
- Typecheck with `uv run pyright scraper/` (only .py files)
- Wrap config.get() returns with str() to satisfy pyright type narrowing
- Use `datetime.now(timezone.utc)` not deprecated `datetime.utcnow()`
- stem library has no type stubs; use `# pyright: ignore[reportAttributeAccessIssue]` for Signal.NEWNYM
- Controller.from_port() `port` param typed as str in stubs; pass str not int
- 2captcha-python: `solver.recaptcha()` can return None; guard before subscripting result
- Import exceptions from twocaptcha: ApiException, NetworkException, TimeoutException, ValidationException
- Playwright ProxySettings TypedDict importable from playwright.async_api; use it instead of plain dict for proxy args
- Store Playwright instance as `Playwright` type (not `object`) to avoid pyright issues on .stop()
- Pre-init loop variables used in except/finally blocks to avoid pyright reportPossiblyUnboundVariable
- CaptchaSolver.solve() is synchronous; safe to call in async without run_in_executor

---

## 2026-02-04 - US-001
- Replaced Michelin config.yaml with CNMC sections (proxy/tor, captcha/2captcha, scraping, database, logging)
- Updated requirements.txt to include 2captcha-python>=1.0
- Set up uv project with pyproject.toml
- Files changed: config.yaml, requirements.txt, pyproject.toml, uv.lock, .python-version
- **Learnings for future iterations:**
  - Existing codebase is a Michelin restaurant scraper; each story will replace modules
  - pyright errors on existing Michelin Python code are pre-existing, will be fixed as modules are rewritten
  - Run typecheck with `uv run pyright scraper/` not on yaml/txt files
---

## 2026-02-04 - US-002
- Replaced Michelin restaurant schema with CNMC portability + progress tables
- upsert_result uses ON CONFLICT ... DO UPDATE for clean upserts
- get_progress returns 0 when no row found, update_progress upserts via ON CONFLICT
- Used str() cast on config.get() return to satisfy pyright type narrowing
- Files changed: scraper/database.py
- **Learnings for future iterations:**
  - config.get() returns Unknown type to pyright; wrap with str() for path params
  - Use `datetime.now(timezone.utc)` instead of deprecated `datetime.utcnow()`
---

## 2026-02-04 - US-003
- Created scraper/csv_reader.py: read_phones() reads single-column CSV, validates 9-digit Spanish mobile (starts 6/7), deduplicates, logs count
- Falls back to config.yaml input_csv when no path arg provided
- Files changed: scraper/csv_reader.py
- **Learnings for future iterations:**
  - Python 3.10+ `str | None` union syntax works fine with pyright, no need for Optional
  - Use re.compile for regex patterns used in loops
---

## 2026-02-04 - US-004
- Rewrote scraper/proxy_pool.py: config-driven ProxyPool class using stem
- rotate_if_needed(query_count) rotates every N (default 9) queries via NEWNYM
- 10s minimum wait between rotations enforced in _rotate()
- Config read from proxy + scraping sections; connect() verifies control port
- Added force_rotate() for immediate rotation on blocks, reset_counter() available
- Files changed: scraper/proxy_pool.py
- **Learnings for future iterations:**
  - stem has no pyright-compatible type stubs; Signal.NEWNYM needs pyright ignore comment
  - Controller.from_port() port param is typed as str in stubs, not int
---

## 2026-02-04 - US-005
- Created scraper/captcha.py: CaptchaSolver class wrapping 2captcha-python SDK
- detect_sitekey(page) extracts reCAPTCHA sitekey via data-sitekey attr or grecaptcha.render regex
- solve(sitekey, page_url) sends to 2Captcha, returns token or None on error
- inject_token(page, token) sets g-recaptcha-response element + triggers reCAPTCHA callbacks
- Handles all 2Captcha exceptions: ApiException, NetworkException, TimeoutException, ValidationException
- Files changed: scraper/captcha.py, prd.json, progress.txt
- **Learnings for future iterations:**
  - solver.recaptcha() return type is Optional; must guard None before subscript
  - twocaptcha package exports exceptions at top level
---

## 2026-02-04 - US-006
- Rewrote scraper/browser.py: CNMC-specific Browser class with Tor SOCKS5 proxy
- Launches Chromium via Playwright with socks5 proxy from config proxy.tor_host/tor_port
- Webdriver masking: navigator.webdriver=false, chrome.runtime, Spanish locale languages
- User agent rotation from predefined list; rotate_user_agent() creates fresh context+page
- navigate_to_form() loads CNMC portability page with networkidle wait
- fill_phone(phone) finds and fills input field
- submit_form() clicks submit/Consultar button
- get_response_html() waits for result selectors then returns page HTML
- Files changed: scraper/browser.py, prd.json, progress.txt
- **Learnings for future iterations:**
  - Import ProxySettings from playwright.async_api for typed proxy dicts
  - Use Playwright type (not object) for _playwright field to get proper .stop() typing
  - Pre-existing errors in main.py/parser.py (old Michelin code): 57 errors, not introduced by this story
---

## 2026-02-04 - US-007
- Rewrote scraper/parser.py: replaced Michelin parser with CNMC portability result parser
- parse_result(html) extracts Número de teléfono, Operador actual, Fecha consulta
- Returns dict {phone, operator, query_date} or None on failure
- Two extraction strategies: regex label>value and table-based <td>label</td><td>value</td>
- _extract_error() handles CNMC error responses (error/alert classes, "no se ha encontrado")
- Files changed: scraper/parser.py, prd.json, progress.txt
- **Learnings for future iterations:**
  - CNMC response format may use either label:value or table layout; parser handles both
  - Old Michelin parser imported compute_content_hash from utils; no longer needed
---

## 2026-02-04 - US-008
- Rewrote scraper/main.py: replaced Michelin two-pass scraper with CNMC phone orchestration loop
- Async entry point with argparse (--input, --reset, --config)
- Loads config, inits DB, reads CSV via csv_reader, checks progress for resume
- Loop: navigate form -> detect/solve captcha -> submit -> parse -> store in DB -> update progress
- Rotates Tor IP every N successful queries via proxy_pool.rotate_if_needed()
- Retries failed queries up to 3x with exponential backoff
- On captcha/block failure: force_rotate() + rotate_user_agent() immediately
- Graceful SIGINT shutdown: saves progress, closes browser and DB
- --reset flag clears progress to 0
- Files changed: scraper/main.py, prd.json, progress.txt
- **Learnings for future iterations:**
  - pyright reportPossiblyUnboundVariable: loop vars like `idx` need pre-init if used in except block
  - signal.signal handler raising exception works for graceful async shutdown
  - CaptchaSolver.solve() is sync (not async); called directly in async context
---

## 2026-02-04 - US-009
- Rewrote scraper/utils.py: replaced basic FileHandler with RotatingFileHandler (10MB, 5 backups)
- Removed Michelin compute_content_hash; logger name now "cnmc_scraper"
- Log level configurable via config.yaml logging.level; max_bytes/backup_count also configurable
- Replaced Michelin README with CNMC docs: prerequisites (Tor, 2Captcha), install via uv, usage, config reference, DB schema
- Deleted Michelin files: additions.txt, proxies.txt, scripts/fetch_proxies.py
- Files changed: scraper/utils.py, README.md, additions.txt (deleted), proxies.txt (deleted), scripts/fetch_proxies.py (deleted)
- **Learnings for future iterations:**
  - RotatingFileHandler from logging.handlers; pass maxBytes and backupCount
  - type: ignore[no-any-return] on yaml.safe_load to satisfy pyright return type
---
